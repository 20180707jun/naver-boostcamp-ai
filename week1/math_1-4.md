# 통계학 맛보기
## 모수가 뭐에요?
- 통계적 모델링은 적절한 가정 위에서 확률분포를 추정하는 것이 목표, 기계학습과 통계학이 공통적으로 추구하는 목표
- 그러나 유한한 개수의 데이터를 관찰해서 모집단의 분포를 정확하게 알아낼 수 없다.
- 따라서 근사적으로 확률분포를 추정한다.
- 데이터가 특정 확률분포를 따른다고 선험적으로 가정 후,
- 그 분포를 결정하는 모수를 추정하는 방법을 모수적 방법론
- 특정 확률분포를 가정하지 않고 데이터에 따라 모델의 구조 및 모수의 개수가 유연하게 바뀌면 비모수 방법론이라고 부른다.

## 확률분포 가정하기
- 데이터가 2개 -> 베르누이분포
- 데이터가 n개의 이산적인 값 -> 카테고리분포, 정규분포
- 데이터가 [0, 1] 사이 -> 베타분포
- 데이터가 0 이상의 값 -> 감마분포, 로그정규분포 등
- 데이터가 R 전체의 값 -> 정규분포, 라플라스분포  

기계적으로 확률분포를 가정해서는 안 되며, 데이터를 생성하는 원리를 먼저 고려하는 것이 원칙

## 데이터로 모수를 추정해보자
-

## 최대가능도 추정법
- 포본평균이나 표본분산은 즁요한 통계량이지만 확률분포마다 사용하는 모수가 다르므로 적절한 통계량이달라진다.
- 이론적으로 가장 가능성이 높은 모수를 추정하는 방법중 하나는 최대가능도 추정법(maximum likelihood estimation, MLE)  
![image](https://user-images.githubusercontent.com/50571795/128439510-83d415c3-63ad-44d6-8039-bface352c6af.png)
- 데이터 집합 X가 독립적으로 추출되었을 경우 로그가능도를 최적화합니다.
![image](https://user-images.githubusercontent.com/50571795/128439602-294b3230-5c39-4c22-bdc3-15cb79b358aa.png)
로그를 이용하면 곱셈연산을 덧셈연산으로 바꿀 수 있다.

### 왜 로그가능도를 사용하는가?
- 데이터가 많아지면 컴퓨터의 정확도로 계산하는 것이 불가능
- 로그를 사용하여 덧셈연산으로 바꾸면 가능해진다.
- 경사하강법으로 가능도를 최적화할 때 미분 연산을 사용하게 되는데, 로그가능도를 사용하면 O(n^2)에서 O(n)으로 연산량이 줄어든다.

# 베이즈 통계학 맛보기

- 베이즈 통계학을 이해하기 위해선 조건부확률의 개념을 이해해야 한다.
- 베이즈 정리는 조건부 확률을 이용하여 **정보를 갱신하는 방법**을 알려줍니다.
![image](https://user-images.githubusercontent.com/50571795/128453251-4b6c4ba0-e718-4072-b5f1-57757d117c6b.png)


### 베이즈 정리를 통한 정보의 갱신
- 베이즈 정리를 통해 새로운 데이터가 들어왔을 때 아퍼 계산한 사후확률을 사전확률로 사용하여 갱신된 사후확률을 계산할 수 있다.
![image](https://user-images.githubusercontent.com/50571795/128455674-eef3d6c7-6f0c-4be3-a89f-3b66516ac9aa.png)

### 조건부 확률->인과관계?
- 조건부 확률은 유용한 통계적 해석을제공하지만 인과관계를 추론할 때 함부로 사용해서는 안된다.