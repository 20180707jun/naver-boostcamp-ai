# 4강 Convolution은 무엇인가?


![image](https://user-images.githubusercontent.com/50571795/129475471-39b17a95-1922-4636-b4d5-1cb035dc6a77.png)  
이 강의에서는 parameter를 세는 것이 상당히 중요  
dense layer는 mlp를 의미한다.(따라서 파라미터가 급증한다.)
## 1x1 Convolution 
사용이유
- 차원 축소
- parameter수 감소시키기
- e.g. bottlenect architecture
# 5강 modern cnn - 1x1 convolution의 중요성

- ILSVRC
  - 연구자 본인이 training하고 test해봤는데 5.1%의 error rate이 나왔다는 후문이 있다.

### AlexNet
- ReLU 사용해서 성능이 좋아짐.
  - 줄어들어서 베니싱확률 적음
  - nonlinear함.
  - data augmentation
- 베니싱 문제를 극복했다.

### VGGNet
- 3x3을 활용했다.
  - 3x3=9, 5x5=25 따라서 3x3은 parameter수를 굉장히 줄일 수 있다.

### GoogleNet
- 1x1 Conv가 들어가는데,
  - parameter 수를 굉장히 줄일 수 있고,
  - concat하는 성질도 좋은 성질.
  - 채널방향으로 차원 축소 가능.  

![image](https://user-images.githubusercontent.com/50571795/129098851-cbcce8f0-0e38-4ba3-9eca-71439b2998ea.png)

### ResNet
- 기존에는 네트워크가 커지면서 학습이 안되는 것이 발생한다.
  - trainning error가 줄고 있는데, test error가 늘어남.
  - 또는 layer가 너무 커서 학습이 안됨.
- network를 더 깊게 쌓을 수 있는 가능성을 열어주었다.
  - residual을 이용해서.
- bottlenect archtecture
  - 1x1 conv하는 것.  

![image](https://user-images.githubusercontent.com/50571795/129475881-65d4f27e-8ffb-4141-ab5c-34a666d71887.png)  
bottlenect architecture
![image](https://user-images.githubusercontent.com/50571795/129475896-a7cca3ed-1360-47f9-8caa-64b54208c9ef.png)  
성능은 좋아지고 파라미터는 줄어들고 있다.
![image](https://user-images.githubusercontent.com/50571795/129099413-d3f86ee6-94cb-4c96-b6f0-81552b92d978.png)

### DenseNet
-  \+ 대신 concat을 한다. 
- concat을 하면 채널이 점점 커진다.
- 따라서, 마지막에 1x1conv로 합친다.
- 분류에서는 결과가 굉장히 잘나옴(분류는 ResNet or DenseNet)  

![image](https://user-images.githubusercontent.com/50571795/129475971-debd997c-3d8a-405a-8686-ab6876f4f993.png)  
두개 블록이 있다.
- Dense Block
  - 계속 concat을 하면서 feature map을 키워나간다.
- Transition Block
  - BatchNorm -> 1x1 Conv -> 2x2 AvgPooling
  - 차원을 축소한다.  
위 두 개 블록을 반복한다.

### Summary
핵심은 이렇다.
- VGG : repeated 3x3 blocks
- GoogLeNet : 1x1 convolution
- ResNet : skip-connection
- DenseNet : concatenation

# 6강 Computer Vision Applications

## Semantic Segmentation
어떤 이미지를 이미지의 의미에 맞게 색칠하는 것.

### Fully Conv Network
![image](https://user-images.githubusercontent.com/50571795/129483677-edb6ab1f-3890-490a-962c-d2ddb16ecee6.png)  

### Deconvolution
- Conv의 역연산
- 하지만 엄밀히 말하면 역연산은 불가능 함.

![image](https://user-images.githubusercontent.com/50571795/129483815-1c25a443-7e2e-4c4a-b97a-b94365675796.png)

## Detecdtion
바운딩 박스를 찾는 것.  
가장 간단한 방법 R-CNN  
2000개의 region을 찾아서 같은 크기로 맞춰서 svm으로 분류함.

### SPPNet
- R-CNN의 문제 2000개를 cnn을 돌려야함.
- 위 문제의 해결방법
  - 이미지에서 바운딩 박스를 뽑고, 이미지 전체에서 cnn을 돌리고
  - 해당위치의 feature map을 뜯어옴.

### Fast R-CNN
- 위의 문제와 거의 비슷한 방법론
- 뒷 단에 RoI feature vector를 통해서 neural net을 이용해서 구현함.

### Faster R-CNN
- 바운딩 박스를 가져오는 Region Proposal Network를 학습시키자.
- = Fast R-CNN + Region Proposal Network

![image](https://user-images.githubusercontent.com/50571795/129484156-e3be5b69-0753-4369-8cad-19b7da7e23d7.png)  
![image](https://user-images.githubusercontent.com/50571795/129484175-e13da210-140e-425f-84d4-b703124cce69.png)

### YOLO(You Only Look Once)
- Faster R-CNN보다 훨씬 빠르다.
- 바운딩 박스를 따로 뽑는 과정이 없다.  
![image](https://user-images.githubusercontent.com/50571795/129484299-0a1d8a8e-adae-477e-af9d-2833c8398a06.png)
